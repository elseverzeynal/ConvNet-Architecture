# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HzsQlrHVLMNMnSdRub-gMMOwFnXINKjE
"""

import torch #for using tensors
import numpy as np
from torchvision import datasets # ready datasets
import torch.nn as nn # creating neural network
from torch.utils.data import DataLoader # creating a data loader
import torch.nn.functional as F # recallable functions like relu,sigmoid and etc.
import torchvision.transforms as transforms # image augmentation
import torch.optim as optim # optimisation functions like sgd, adam
from torch.utils.data.sampler import SubsetRandomSampler # creating a data loader

torch.cuda.is_available()

#chech if cuda is available'
train_on_gpu = torch.cuda.is_available()
if not train_on_gpu:
  print('Cuda is not available. Training on CPU...')
else:
  print('Cuda is available. Training on GPU...')

# Hyperparameters
num_workers = 0 #data boyuk olanda 1 ya 2 qoymaq olar ki model daha rahat islesin
batch_size = 20
valid_size = 0.2

# transforms to apply to the data
transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((150, 150)),transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])

# dataset
train_data = datasets.ImageFolder(root='/content/drive/MyDrive/Data/seg_train', transform=transform)
test_data = datasets.ImageFolder(root="/content/drive/MyDrive/Data/seg_test", transform=transform)

#getting index that will be used for validation
num_train=len(train_data)
indices=list(range(num_train))
np.random.shuffle(indices)
split=int(valid_size*num_train)
train_idx,valid_idx=indices[split:],indices[:split]
#define samplers for obtaining training and validation batches
train_sampler=SubsetRandomSampler(train_idx)
valid_sampler=SubsetRandomSampler(valid_idx)

#prepare data loaders
train_loader = DataLoader(train_data,batch_size=batch_size,sampler=train_sampler,num_workers=num_workers)
valid_loader = DataLoader(train_data,batch_size=batch_size,sampler=valid_sampler,num_workers=num_workers)
test_loader = DataLoader(test_data,batch_size=batch_size,num_workers=num_workers,drop_last=True)
#specify image classes
classes=['buildings','forest','glacier','mountain','sea','street']

for images,labels in train_loader:
    print(images.shape)
    break

#visualization of images
import torchvision
import matplotlib.pyplot as plt
batch = next(iter(train_loader))
grid = torchvision.utils.make_grid(batch[0], nrow=8)
# Plot the grid
plt.figure(figsize=(10, 10))
plt.imshow(grid.permute(1, 2, 0))
plt.axis('off')
plt.show()

class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()# first 3 lines is mandatory for inheriting properties of model
        self.conv1 = nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,padding=1)
        self.pool = nn.MaxPool2d(2,2)
        self.fc1 = nn.Linear(16*75*75,64)
        self.fc2 = nn.Linear(64,64)
        self.fc3 = nn.Linear(64,6)
        self.dropout = nn.Dropout(p=0.5)
    def forward(self,x):
        #3.150.150
        x = self.pool(F.relu(self.conv1(x)))
        #16.150.150->16.75.75
        x = x.view(-1,16*75*75)
        x = self.dropout(F.relu(self.fc1(x)))
        x = self.dropout(F.relu(self.fc2(x)))
        x = self.fc3(x)
        return x

model=NeuralNetwork()
if train_on_gpu:
  model.cuda()

def get_n_params(model):
  pp=0
  for p in list(model.parameters()):
    nn=1
    for s in list(p.size()):
      nn=nn*s
    pp += nn
  return pp

get_n_params(model)

# Loss and optimizer
criterion = nn.CrossEntropyLoss() #loss function for defining if we  predicted right or wronge
optimizer = torch.optim.SGD(model.parameters(), lr=.01) # optimisation function for creating gradient decent and learning

num_epochs = 10  # how many times model will go back and forth

# Train the model
total_step = len(train_loader)
train_losslist = []
valid_losslist = []
valid_loss_min = np.Inf
for epoch in range(1,num_epochs+1):
  train_loss = 0.0
  valid_loss = 0.0
  model.train()
  for data,target in train_loader:
    if train_on_gpu:
      data,target=data.cuda(),target.cuda()
      # Backprop and perform Adam optimisation
    optimizer.zero_grad()
    output=model(data)
    loss=criterion(output,target)
    loss.backward()
    optimizer.step()
    train_loss+=loss.item()*data.size(0)
  model.eval()
  for data,target in valid_loader:
    if train_on_gpu:
      data,target=data.cuda(),target.cuda()
    output=model(data)  
    loss=criterion(output,target)
    valid_loss+=loss.item()*data.size(0)
  train_loss=train_loss/len(train_loader.dataset)
  valid_loss=valid_loss/len(valid_loader.dataset)
  train_losslist.append(train_loss)
  valid_losslist.append(valid_loss)
  print('Epoch {} \tTraining Loss: {:6f}, \tValidation Loss: {:.6f}'.format(
      epoch,train_loss,valid_loss))
  if valid_loss <=valid_loss_min:
    print('Validation loss decreased ({:.6f}-->{:.6f}). Saving Model ... '.format(
    valid_loss_min,
    valid_loss))
    torch.save(model.state_dict(),'model_cifar.pt')
    valid_loss_min=valid_loss

plt.plot(range(1,num_epochs+1),train_losslist)
plt.xlabel('Epochs')
plt.xlabel('Loss')
plt.title('Performance of Model')
plt.show()

test_loss=0.0
class_correct = list(0. for i in range(6))
class_total = list(0. for i in range(6))

model.eval()
for data, target in test_loader:
  if train_on_gpu:
    data,target=data.cuda(),target.cuda()
    output = model(data)
    loss=criterion(output,target)
    test_loss+=loss.item()*data.size(0)
    _, pred = torch.max(output, 1)
    correct_tensor = pred.eq(target.data.view_as(pred))
    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu())
    for i in range(batch_size):
      label=target.data[i]
      class_correct[label]+=correct[i].item()
      class_total[label] +=1
test_loss=test_loss/len(test_loader.dataset)
print('Test Loss: {:.6f}\n'.format(test_loss))

for i in range(6):
  if class_total[i]>0:
    print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (
        classes[i],100 * class_correct[i] / class_total[i],
        np.sum(class_correct[i]),np.sum(class_total[i])))
  else:
    print('Test Accuracy of %5s: N/A (no training example)'% (classes[i]))
print('\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (
        100. * np.sum(class_correct) / np.sum(class_total),
        np.sum(class_correct),np.sum(class_total)))

# Save the model
file_path = 'model2.ckpt'
torch.save(model.state_dict(), file_path)

#Load model
 model.load_state_dict(torch.load(file_path))

import os
from PIL import Image
from torch.utils.data import Dataset, DataLoader

class ImageFolderDataset(Dataset):
    def __init__(self, root, transform=None):
        self.root = root
        self.transform = transform
        self.images = os.listdir(root)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, index):
        image_path = os.path.join(self.root, self.images[index])
        image = Image.open(image_path).convert('RGB')
        if self.transform is not None:
            image = self.transform(image)
        return image

pred_data = ImageFolderDataset(root="/content/drive/MyDrive/Data/seg_pred", transform=transform)

pred_loader = DataLoader(pred_data)

import os
model.eval()
with torch.no_grad():
    g = 0
    for images in pred_loader:
        images=images.cuda()
        outputs = model(images)
        predicted = torch.max(outputs.data, 1)[1]
        for i in range(len(predicted)):
          torchvision.utils.save_image(images[i], f"{os.getcwd()}\\Data\\classed_pred\\{classes[predicted[i]]}\\generated image{g}.JPG",normalize=True)
          if (g+1) % 1000 ==0:
            print(f'{g+1} pictures done!')
          g += 1